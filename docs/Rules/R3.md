# Smell: “TensorArray Not Used”

## Motivation  
In TensorFlow a tensor that is grown iteratively inside a Python `for` / `while`
loop (e.g. by calling `tf.concat` or `tf.stack` at every iteration) is highly
inefficient: a new, larger tensor is re-allocated each time.  
TensorFlow’s dedicated `tf.TensorArray` API avoids this cost by pre-allocating
a buffer and writing into it.  
Our rule therefore looks for situations where a developer
*builds a tensor step-by-step inside a loop* but never uses a `TensorArray`.

---

## Detection strategy (high-level view)

1. **AST parsing and parent links**  
   The file is parsed into its Abstract Syntax Tree (AST).  
   During a preparatory pass every node receives a reference to its parent so
   that we can later determine whether a given operation is **inside** a loop.

2. **Collect tensor constants**  
   Still within the loop’s scope we record variables that are initialised by  
   `tf.constant`, `tf.ones`, `tf.zeros`, `tf.Variable`, etc.  
   These variables form the set _tensor-constants_ we want to monitor.

3. **Ignore legitimate usages**  
   A tensor that is **only** passed to `TensorArray.write()` is harmless and is
   therefore removed from the watch-list.

4. **Spot suspicious growth patterns**  
   While traversing the loop body we flag a statement when:  
   • it assigns the result of `tf.concat` or `tf.stack` **to one of the watched
     tensors**, or  
   • it re-assigns such a tensor through an arithmetic operation
     (`tensor = tensor + …`, `tensor *= …`, …).  
   These patterns all indicate that the tensor is being rebuilt repeatedly
   instead of being stored in a `TensorArray`.

5. **Reporting**  
   For every loop (or function that contains a loop) where at least one of the
   above patterns is found, the detector records the line number and issues:




---

## Practical meaning for the developer  
The warning pinpoints the loop where the tensor is grown imperatively.
Replacing the `tf.concat` / `tf.stack` (or equivalent in-place arithmetic) with
a `tf.TensorArray` followed by a single `stack()` at the end will drastically
reduce memory copies and speed up execution.

---

## Limitations  
* It only recognises the standard `tf` alias (`import tensorflow as tf`).  
* If the growth happens inside a nested helper that the rule cannot inspect,
  it may miss the smell.  
* Cases where a tensor is enlarged **outside** an explicit Python loop (e.g.,
  via `tf.while_loop`) are not covered by this particular rule.
