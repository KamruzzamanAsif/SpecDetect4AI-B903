# Smell: Data Leakage 

## Motivation  
Performing **feature scaling or other data‑dependent transforms on the whole
dataset *before* the train / test split** leaks information from the hold‑out
portion into the model‑building phase.  
Similarly, applying `model.fit()` on pre‑processed data **without wrapping the
steps in a `Pipeline`** allows hidden leakage when the same workflow is reused
for inference.

Consequences:

* Over‑optimistic cross‑validation scores,  
* Poor generalisation on truly unseen data,  
* Undetected bias in automated ML pipelines.

Typical safe workflow:

```python
pipe = make_pipeline(StandardScaler(), LogisticRegression())
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)
pipe.fit(X_train, y_train)
score = pipe.score(X_test, y_test)
```

---


## Detection strategy (high-level view)

The original rule was split into **R11** and **R11 bis** for finer reporting,
but they stem from the same logic.

| Sub‑rule | What it flags | Core test |
|----------|---------------|-----------|
| **R11** | Calling **`fit_transform`** (or equivalent) **before** any `train_test_split`, *and not inside a pipeline*. | `isFitTransform(node)  &&  usedBeforeTrainTestSplit(node) && !pipelineUsed(node)` |
| **R11 bis** | Running **`model.fit()`** when *some* scaling / encoding has been applied, **but no `Pipeline` is declared anywhere in the file**. | `isModelFitPresent(ast)  &&  !pipelineUsedGlobally(ast)` |

Both sub‑rules share helper analyses:

* Detect variables returned by scaler `.fit_transform()`  
  (`gather_scaled_vars`).  
* Check if a call is part of a `Pipeline` (`pipelineUsed`, `pipelineUsedGlobally`).  
* Verify the chronological order of lines (`usedBeforeTrainTestSplit`).  

Report messages:

```
REPORT: Potential data leakage: fit_transform called before train/test split at line `n`
REPORT: Potential data leakage: model.fit() used without a pipeline at line `n`
```


---

## Practical meaning for the developer  
*Move preprocessing into a scikit‑learn `Pipeline` or perform it **inside** the
cross‑validation folds.*

```python
# BAD  – leaks test info
X_scaled = StandardScaler().fit_transform(X)   # <-- uses entire dataset
X_train, X_test = train_test_split(X_scaled, ...)

# GOOD – leak‑free
pipe = make_pipeline(StandardScaler(), LogisticRegression())
X_train, X_test = train_test_split(X, ...)
pipe.fit(X_train, y_train)
```

---
## Limitations

- The rule inspects a **single Python file**; if splitting happens in a
  different script, leakage may go undetected.  
- Only transformers using `.fit_transform()` are covered; custom classes with
  separate `fit` / `transform` may evade detection.  
- The check does not detect leakage introduced by *target* preprocessing
  (`y_log = np.log1p(y)` before split).  