# Smell: Model.fit called without Early-Stopping

## Motivation  

When training deep-learning models (Keras / TensorFlow, PyTorch-Lightning, etc.)
it is common to train for too many epochs and over-fit the training data.
A simple safeguard is the `EarlyStopping` callback:

```python
model.fit(
    X_train, y_train,
    epochs=200,
    callbacks=[keras.callbacks.EarlyStopping(
        monitor="val_loss", patience=5, restore_best_weights=True)]
)
```

Without it you risk:

- wasted compute time after the validation loss stagnates,  
- over-fitted weights and poorer generalisation,  
- tedious manual monitoring of the training curves.


---

## Detection strategy (high‑level view)

1. **AST parsing**  
   The tree is built and enriched with parent links (`add_parent_info` predicate).

2. **Collect scale-sensitive estimators**  
    Side work the file already does; not needed for this rule.

3. **Locate every `.fit()` call**
    `isFitCall(node)` return `true` when the attribute name is "fit".

4. **Check the callbacks keyword**
    `hasEarlyStoppingCallback(node)` scans the keywords list looking for the callbacks argument and searches its source for the substring `EarlyStopping`.

5. **Reporting**  

   If a .fit() has no EarlyStopping callback, emit  
   REPORT: Model.fit() called without EarlyStopping callback at line `n `.



---

## Practical meaning for the developer 


### Missing EarlyStopping
```python
model = build_model()
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=200                 #  runs full length, may over-fit
)
```

### Refactor
```python
early_stop = keras.callbacks.EarlyStopping(
    monitor="val_loss", patience=5, restore_best_weights=True
)
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=200,
    callbacks=[early_stop]     #  stops automatically
)
```


---

## Limitations  

- The rule only looks for the literal string `"EarlyStopping"`  inside the callbacks argument; custom wrappers or aliases (`MyEarlyStop, cb_list.append(EarlyStopping()`), etc.) are missed.

- It does not analyse callback construction occurring earlier and stored
  in a variable (`cbs = [EarlyStopping(...)]`) unless that variable’s
  source code keeps the string `“EarlyStopping”`.

- It does not inspect configuration of other early-exit mechanisms
  (`ReduceLROnPlateau, PyTorch-Lightning’s` Trainer parameters, etc.).

- False positives possible if `fit()` comes from non-Keras APIs that do not
  accept callbacks.

