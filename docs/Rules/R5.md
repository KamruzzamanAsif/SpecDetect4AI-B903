# Smell: “Hyperparameter Not Explicitly Set”

## Motivation  
Most machine-learning estimators, optimisers and neural-network layers expose
hyperparameters whose default values are **only safe fall-backs**.  
Leaving them untouched can lead to:

* sub-optimal accuracy or convergence,
* results that silently change after a library upgrade (defaults may evolve),
* experiments that are hard to reproduce or compare.

Therefore the rule flags every constructor call that creates a
hyperparameter-rich object but passes **no keyword arguments at all**.

---

## Detection strategy (high-level view)

1. **AST parsing**  
   The source file is transformed into its Abstract Syntax Tree so each
   constructor call can be inspected structurally.

2. **Catalogue of “hyperparameter-rich” classes / functions**  
   A hand-crafted set contains the most common objects whose behaviour is
   governed by tunable parameters, e.g.  
   • Scikit-Learn: `RandomForestClassifier`, `KMeans`, `LogisticRegression`, …  
   • PyTorch: `torch.optim.SGD`, `Adam`, …  
   • TensorFlow / Keras: `Dense`, `Conv2D`, `Adam`, …  
   • XGBoost / LightGBM: `XGBClassifier`, `LGBMRegressor`, …

3. **Identify suspicious calls**  
   During a single walk the rule marks a node as **problematic** when  
   a) the callee’s fully-qualified name is in the catalogue, **and**  
   b) the `ast.Call` node contains **zero** keyword arguments  
      (`len(call.keywords) == 0`).

4. **Reporting**  
   For each such node the detector emits
   REPORT: Hyperparameter not explicitly set at line `n`
   with `n` pointing at the constructor line, inviting the developer to add the missing arguments.

---

## Practical meaning for the developer  
Always specify the hyperparameters that influence model capacity, learning
rate, regularisation strength, number of estimators, etc., for example:

```python
# BEFORE  – will raise the smell
model = RandomForestClassifier()       

# AFTER   – explicit, reproducible, no smell
model = RandomForestClassifier(
 n_estimators=300,
 max_depth=12,
 random_state=42
)
```
Stating them explicitly makes the experiment:

- Reproducible across machines and library versions, 
- Easier to tune systematically (grid / random / Bayesian search),  
- Clearer for reviewers and future maintainers.

## Limitations

- The catalogue is finite; a custom estimator or an unlisted third-party
class will not be caught.  
- The rule works per file; if the object is instantiated with defaults and
tuned later via set_params, the detector will raise a false positive.  
- It only checks that some keyword arguments are present, not that the
most relevant ones are set.  
Chained factory patterns (e.g. sklearn.pipeline.make_pipeline(...) .set_params(...)) may evade detection.