# Smell: Unnecessaryâ€¯Iteration

## Motivation  

Iterating rowâ€‘byâ€‘row over a Pandas DataFrame using `iterrows() / itertuples()` or looping in Python over TensorFlow tensors is almost always a performance smell:

It prevents the libraries from leveraging native C/NumPy kernels or GPU ops.

It silently scalesÂ `ğ‘‚(n)` Python overhead, which becomes dramatic on large data.

In TF graphs it can inhibit autoâ€‘vectorisation and XLA fusion.

Modern dataâ€‘science APIs already expose vectorised alternatives (e.g. `df["a"] + df["b"], DataFrame.apply, tf.reduce_sum, tf.math.add`) that are clearer and much faster.

---

## Detection strategy (highâ€‘level view)

1. **AST parsing**  
   The source file is transformed into its Abstract Syntax Tree so each
   constructor call can be inspected structurally.

2. **Loop identification**  
     Every `ast.For` node is inspected.

3. **Iterationâ€‘pattern tests**
    A loop is flagged when any of these hold:

    The iterator is a call to `DataFrame.iterrows()` and the base object is recognised as a DataFrame.

    The iterator is a call to `DataFrame.itertuples()` on a DataFrame.

    The loop body performs arithmetic on TensorFlow tensors in pureâ€‘Python (detected via `tf.*` ops inside the loop).

4. **Reporting**  

   When such a node is found the detector emits 
   REPORT: Unnecessary iteration detected; consider using vectorized operations â€¦ at lineÂ `n `

   with `n` pinpointing the loop head.
---



---

## Practical meaning for the developer 


### Pandas
```python
# BEFORE â€“ rowâ€‘wise Python loop (~600â€¯ms on 1â€¯M rows)
for _, row in df.iterrows():
    df.loc[_, "total"] = row["a"] + row["b"]

# AFTER  â€“ vectorised (~35â€¯ms)
df["total"] = df["a"] + df["b"]
```

### Tensorflow

```python
# BEFORE â€“ Python loop on tensors
result = tf.constant(0.)
for i in range(x.shape[0]):
    result += x[i] * y[i]

# AFTER â€“ fused kernel
overlap = tf.reduce_sum(x * y)
```

---

## Limitations  

- The rule is conservative â€“ it does not flag DataFrame loops when the
iterator is already vectorised (e.g. for chunk in `pd.read_csv(..., chunksize=â€¦)`).

- In notebook code smallâ€‘data exploration may be acceptable; the smell focuses
on production / batch pipelines.

- The TensorFlow subâ€‘rule relies on simple heuristics; exotic controlâ€‘flow may
evade detection.

**Bottomâ€‘line**: If you see yourself writing `forÂ â€¦ in df.iterrows()` or looping over tensors, pause and reach for a vectorised/DataFrame/TF operation instead.

