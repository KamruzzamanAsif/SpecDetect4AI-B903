# Smell: “Deterministic Algorithm Option Not Used”


## Motivation  
Since `PyTorch` 1.8 the library only guarantees bit-wise reproducibility when the global flag  
`torch.use_deterministic_algorithms(True)` is enabled before any tensor operation is executed.

If the flag is missing, ``PyTorch`` may pick non-deterministic CUDA kernels or faster but non-repeatable CPU paths; two runs of the same script can therefore yield different weights, losses or predictions.
---

## Detection strategy (high-level view)

1. **AST parsing**  
   The source file is transformed into its Abstract Syntax Tree so each
   constructor call can be inspected structurally.

2. **Three concurrent checks in one tree walk**  
   • `PyTorch` imported? – detect import torch or from torch ….
   • `PyTorch` actually used? – flag any call whose fully-qualified name starts with torch. (e.g. `torch.tensor`, `torch.nn.Linear`).
   • Determinism flag set? – search for a call to `torch.use_deterministic_algorithms` whose first positional argument is the Boolean literal `True`.

3. **Decision rule**  
   Report the smell whena) PyTorch is imported,
   b) some PyTorch API call occurs **and**
   c) no deterministic-algorithm flag is found anywhere in the file.

4. **Reporting**  
   The detector emits  
    REPORT: Deteministic Algorithm Option Not Used at line `n`  
    where `n` is (for convenience) the line of the first torch statement, i.e. roughly where the missing flag should be added.

---

## Practical meaning for the developer  
Add, once near the top of your main script, the lines:
```python
import torch
torch.use_deterministic_algorithms(True)
```

Doing so locks all subsequent operations into their deterministic variants and removes run-to-run variability.
For full reproducibility you should also:  

- seed every RNG you rely on (`torch.manual_seed`, `np.random.seed`, `random.seed`, …);  
- disable CuDNN benchmarking when relevant (`torch.backends.cudnn.benchmark` = `False`).

## Limitations

- Only the canonical module name torch is recognised; exotic aliases such as import torch as th are not detected.  
- The analysis is per file; if the flag is set in another module imported later, a false positive will occur.  
- The rule only verifies that `torch.use_deterministic_algorithms(True)` is present; it does not check complementary settings like `torch.backends.cudnn.deterministic = True`.