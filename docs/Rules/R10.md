# Smell: Memory Not Freed

## Motivation  
Deepâ€‘learning experiments often build **temporary tensors or models inside loops** (e.g. gridâ€‘search, data augmentation, batch processing).  
If those objects are *not* explicitly released, GPU / CPU memory keeps growing and can lead to:

* **Outâ€‘ofâ€‘memory (OOM) crashes**,  
* Degraded training speed due to frequent GC or pageâ€‘faults,  
* Hidden leaks that only appear in longâ€‘running production services.

Typical cleanup patterns are:

```python
loss = model(x).mean()
loss.backward()
optimizer.step()

# ðŸš½  Free memory
loss.detach()              # PyTorch â€“ drop computation graph
del loss, x
torch.cuda.empty_cache()   # optional
```

or, for Keras / TensorFlow:

```python
from tensorflow.keras import backend as K
...
K.clear_session()          # clear graph & release GPU memory
```

---

## Detection strategy (high-level view)

1. **AST parsing**  
   The source file is transformed into its Abstract Syntax Tree so each
   constructor call can be inspected structurally.

2. **Heavy object detection**  
   Mark every node that **creates** a heavy object: 
   â€¢Â PyTorch tensor constructors `torch.tensor(...)`, `torch.Tensor(...)`
   â€¢Â Highâ€‘level layer / model builders (`Sequential`, `Dense`, `Conv2D`, â€¦).


3. **Free calls detection**  
   Search the same file for **memoryâ€‘freeing calls**:
   â€¢Â `tensor.detach()` or `tensor = None` (PyTorch)
   â€¢Â `backend.clear_session()` or `clear_session()` (Keras/TensorFlow)
   â€¢Â Explicit `del var`Â statements.

4. **Reporting**  

   If **some** heavyâ€‘object creations exist **and** **none** of the cleanup APIs are present, emit a warning.
   The detector emits  
    Memory clearing API not used. Consider calling .detach() for PyTorch or tf.keras.backend.clear_session() for TensorFlow at line`n`.

---

## Practical meaning for the developer  
### In PyTorch  

```python
for batch in loader:
    out = model(batch)
    loss = criterion(out, y)

    loss.backward()
    optimizer.step()
    optimizer.zero_grad()

    #  Free graph & batch tensors
    loss.detach()
    del out, loss, batch
```

### In TensorFlow / Keras*  

```python
for cfg in hyperparams_grid:
    model = build_model(cfg)
    model.fit(X, y)

    #  Release GPU memory of the old graph
    tf.keras.backend.clear_session()
```

---
## Limitations

- Interâ€‘file lifetime: if the script frees memory in a **different file**, the rule
  may raise a false positive.  
- The check does **not** verify *where* in the loop the cleanup happens â€“ only that at
  least one freeing call exists somewhere in the file.  
- Custom wrappers (e.g. `free_gpu()`) need to be added to the whitelist
  `isMemoryFreeCall()` to be recognised.  