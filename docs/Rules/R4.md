# Smell: “Training / Evaluation Mode Improper Toggling”

## Motivation  
In PyTorch a model behaves differently depending on whether it is in  
• **training mode** (`model.train()`) or  
• **evaluation / inference mode** (`model.eval()`).  

Layers such as `Dropout`, `BatchNorm`, `InstanceNorm`, etc. internally switch
their behaviour when the flag changes:

* Dropout is **active** during training, **disabled** during inference.  
* Batch-normalisation accumulates running statistics during training but
  **freezes** them during inference.

If a developer calls `.eval()` to run an intermediate validation step and then
forgets to switch back to `.train()`, the subsequent training iterations will
silently use the wrong behaviour, leading to poor convergence or misleading
metrics.

---

## Detection strategy (high-level view)

1. **AST parsing & parent links**  
   The file is parsed into its Abstract Syntax Tree (AST) and each node is
   annotated with a pointer to its parent so that the analysis can reason about
   statement order.

2. **Record the position of every `.eval()` and `.train()` call**  
   During a single walk the rule collects the line numbers of  
   • calls whose attribute is `eval`,  
   • calls whose attribute is `train`.

3. **Flag suspicious patterns**  
   For every `model.eval()` occurrence the tool asks:  
   “Is there any `.train()` call on the **same object** **later** in the file?”  
   If the answer is **no**, the detector considers the toggle incomplete and
   marks the `.eval()` line as problematic.

4. **Reporting**  
   Each offending site is reported as
   REPORT: Training / Evaluation Mode Improper Toggling: .eval() call without subsequent .train() call at line `n` where `n` is the exact line number of the dangling `.eval()` invocation.

---

## Practical meaning for the developer  
Always revert the model back to training mode once the validation / inference
block is finished, e.g.:

```python
model.eval()
with torch.no_grad():
 val_loss = validate(...)
model.train()        # <-- missing ⇒ smell reported
```

Failing to do so usually manifests in:

validation accuracy that suddenly looks too good (because dropout is off during the next training batches), or training that never converges when normalisation statistics stop updating.


## Limitations

The rule only checks syntactic order inside a single source file; if
.train() is invoked in a different module imported later, a false positive
will appear.  
It assumes the call is made directly on the model variable
(model.eval(), model.train()). If the model is stored inside a container
(e.g. models[idx].eval()) the detector may miss the relation.  
Framework-specific aliases (net.eval(), classifier.train(), …) are
recognised as long as they use the standard method names eval / train.